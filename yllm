#!/bin/bash

YLLM_MAX_TOKENS=4096
YLLM_TEMPERATURE=0.1
YLLM_TOP_P=0.9

function print_help() {
  cat <<EOF
Usage: $0 [options] [--] [prompt]

Options:
  -h, --help                Print this help text and exit.
  -s, --settings <file>     Load YLLM_* env settings from the given file.
  -a, --api-url <url>       The API URL to use (default: $YLLM_API_URL).
  -k, --api-key <key>       The API key to use (default: $YLLM_API_KEY).
  -m, --model <model>       The model to use for the completion (default: $YLLM_MODEL).
  -t, --temperature <t      The temperature for the model (default: $TEMPERATURE).
  -p, --top-p <p>           The top-p value for the model (default: $TOP_P).
  -l, --max-tokens <n>      The maximum number of tokens to generate (default: $MAX_TOKENS).
  -c, --stdin               Read data from standard input.
  -u, --url <url>           Read text data from the given URL.
  -f, --file <file>         Read text data from the given file.
  -d, --dump-prompt         Write the prompt to stdout and exit.
  -r, --raw-stream          Show the raw JSONL stream from the API.
  -z, --save-it <dir>       Write inputs and outputs to hash-named file in dir.

If no prompt is provided, read from standard input.
The prompt is built from input arguments in the order they are provided.
EOF
}

# no arguments, print help
if [[ $# -eq 0 ]]; then
  print_help
  exit 0
fi

# Parse command line arguments and flags
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            print_help
            exit 0
            ;;
        -s|--settings)
            SETTINGS_FILE="$2"
            # Check if the specified settings file exists in the current directory
            if [[ -f "$SETTINGS_FILE" ]]; then
                source "$SETTINGS_FILE"
            # If not found, check in the ~/.yllm directory
            elif [[ -f "$HOME/.yllm/$SETTINGS_FILE" ]]; then
                source "$HOME/.yllm/$SETTINGS_FILE"
            else
                echo "Settings file not found: $SETTINGS_FILE"
                exit 1
            fi
            shift # past argument
            shift # past value
            ;;
        -a|--api-url)
            YLLM_API_URL="$2"
            shift # past argument
            shift # past value
            ;;
        -k|--api-key)
            YLLM_API_KEY="$2"
            shift # past argument
            shift # past value
            ;;
        -m|--model)
            YLLM_MODEL="$2"
            shift # past argument
            shift # past value
            ;;
        -t|--temperature)
            YLLM_TEMPERATURE="$2"
            shift # past argument
            shift # past value
            ;;
        -p|--top-p)
            YLLM_TOP_P="$2"
            shift # past argument
            shift # past value
            ;;
        -l|--max-tokens)
            YLLM_MAX_TOKENS="$2"
            shift # past argument
            shift # past value
            ;;

        -c|--stdin)
            STDIN_CONTENT=$(cat)
            inputs+=("$STDIN_CONTENT")
            shift # past argument
            ;;
        -u|--url)
            URL_CONTENT="$(curl -s "$2" | lynx -stdin -dump)"
            inputs+=("$URL_CONTENT")
            shift # past argument
            shift # past value
            ;;
        -f|--file)
            FILE="$2"
            mimetype=$(file -b --mime-type "$FILE")
            if [[ $mimetype == text/* ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "inode/symlink" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/pdf" ]]; then
                FILE_CONTENT="$(pdftotext "$FILE" -)"
            elif [[ $mimetype == "application/json" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/javascript" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/x-ndjson" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/epub+zip" ]] \
                || [[ $mimetype == "application/vnd.openxmlformats-officedocument.wordprocessingml.document" ]] \
                || [[ $mimetype == "application/msword" ]] \
                || [[ $mimetype == "application/postscript" ]]; then
                FILE_CONTENT="$(pandoc -s "$FILE" -t plain -o -)"
            else
                echo "Unsupported file type: $(file -b --mime-type "$FILE")"
                exit 1
            fi
            inputs+=("$FILE_CONTENT")
            shift # past argument
            shift # past value
            ;;
        -d|--dump-prompt)
            DUMP_PROMPT=1
            shift # past argument
            ;;
        -r|--raw-stream)
            RAW_STREAM=1
            shift # past argument
            ;;
        -z|--save-it)
            YLLM_SAVE_IT="$2"
            shift # past argument
            shift # past argument
            ;;
        *)
            inputs+=("$1")
            shift # past argument
            ;;
    esac
done

# if we should dump the prompt
if [[ $DUMP_PROMPT ]]; then
    printf "%s\n" "${inputs[@]}"
    exit 0
else
    # if no model has been specified
    if [[ -z "$YLLM_MODEL" ]]; then
        echo "No model specified. Please set the YLLM_MODEL environment variable, use the -m option, or specify a config file."
        exit 1
    fi
fi

unbuffer="stdbuf -o0 -i0"

send_request() {
    prompt="$1"
    if [[ $YLLM_DEEPINFRA_MODE ]]; then
    prompt=$(echo "$prompt" | sed -e 's/\[INST\]//g' -e 's/\[\/INST\]//g')
    json_payload='{
        "input": '$prompt',
        "stream": true
    }'
    elif [[ $YLLM_COHERE_WEB_MODE ]]; then
    json_payload=$(printf '{
        "message": %s,
        "stream": true,
        "connectors": [{"id": "web-search"}],
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    elif [[ $YLLM_COHERE_MODE ]]; then
    json_payload=$(printf '{
        "message": %s,
        "stream": true,
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    else
    json_payload=$(printf '{
        "messages": [
            {
                "role": "user",
                "content": %s
            }
        ],
        "model": "%s",
        "stream": true,
        "n": 1,
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" "$YLLM_MODEL" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P )
    fi

    json_payload=$(echo "$json_payload" | jq -c .)

    temp_file=$(mktemp)
    echo "$json_payload" > "$temp_file"

    cleanup() {
        [[ -n $temp_file && -f $temp_file ]] && rm -f "$temp_file"
    }

    trap cleanup EXIT

    #cat $temp_file

    $unbuffer curl --request POST \
         --silent \
         --url "$YLLM_API_URL" \
         -H 'content-Type: application/json' \
         -H "authorization: Bearer $YLLM_API_KEY" \
         $YLLM_EXTRA_CURL_FLAGS \
         --data @"$temp_file"
}

COMPLETE_PROMPT=$(printf "%s\n" "${inputs[@]}" | jq -sR .)

if [[ $RAW_STREAM ]]; then
    send_request "$COMPLETE_PROMPT"
    exit 0
fi

if [[ $YLLM_SAVE_IT ]]; then
    hash=$(echo -n "$COMPLETE_PROMPT" | sha256sum | awk '{print $1}' | head -c 8)
    output_file_base=$(mktemp -p "$YLLM_SAVE_IT" yllm_$hash.XXXXXX)
    rm -f "$output_file_base"
    output_file=$output_file_base.md
    output_raw=$output_file_base.jsonl
else
    output_file=/dev/null
    output_raw=/dev/null

fi

# Send the request and extract the response
# do this if we're not in deepinfra mode
if [[ $YLLM_DEEPINFRA_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer sed 's%</s>"%"%' \
    | $unbuffer sed 's/^data: //g' | $unbuffer sed 's/\[DONE\]//' \
    | $unbuffer jq -j --unbuffered 'select(.token.text != null) | .token.text' \
    | tee $output_file
elif [[ $YLLM_COHERE_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
        | $unbuffer jq -j --unbuffered 'select(.event_type == "text-generation") | if .is_finished then "\n" else .text end' \
        | tee $output_file
elif [[ $YLLM_COHERE_WEB_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
        | tee $output_raw \
        | $unbuffer jq -j --unbuffered 'select(.event_type == "text-generation") | if .is_finished then "\n" else .text end' \
        | tee $output_file

    if [[ $YLLM_SAVE_IT ]]; then
        # Extract the documents and citations from the JSON record
    jq 'select(.event_type == "stream-end")' $output_raw >$output_raw.end
    (python3 - "$output_raw.end" <<'EOF'
import json
import sys

infile = sys.argv[1]

# Load the model output from a file
with open(infile, 'r') as file:
    record = json.load(file)

# Extract the main text, citations, and documents from the JSON record
main_text = record['response']['text']
citations = record['response']['citations']
documents = {doc['id']: doc for doc in record['response']['documents']}

# Initialize an empty string to hold the annotated text
annotated_text = ""
last_pos = 0  # Keep track of the last position processed

# Iterate over the citations
for citation in citations:
    # Add the text from the last position to the start of the current citation
    annotated_text += main_text[last_pos:citation['start']]
    
    # Add the citation text
    citation_text = main_text[citation['start']:citation['end']]
    annotated_text += citation_text

    # Prepare to add links
    links = []
    
    # Construct the markdown links for each document in the citation
    for doc_id in citation['document_ids']:
        # Extract the document index from the ID and increment by 1 for natural numbering
        doc_index = doc_id.split('_')[-1].split(':')[0]
        # Extract the actual URL for the document
        url = documents[doc_id]['url'] if doc_id in documents else "xxxxx"
        # Append the markdown link to the links list
        # (as long as it's not a duplicate)
        if url not in links:
            links.append(f"[{doc_index}]({url})")
    
    # Join all links with a comma and add them in a single set of brackets
    annotated_text += f" [{','.join(links)}]"
    
    # Update the last processed position
    last_pos = citation['end']

# Add any remaining text after the last citation
annotated_text += main_text[last_pos:]

# Print the annotated markdown text
print(annotated_text)
EOF
    ) > $output_file
    rm -f $output_raw.end
    fi
else
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer sed 's%</s>"%"%' \
    | $unbuffer sed 's/^data: //g' | $unbuffer sed 's/\[DONE\]//' \
    | $unbuffer jq -j --unbuffered 'select(.choices[0].delta.content != null) | if .choices[0].finish_reason == "stop" then .choices[0].delta.content + "\n" else .choices[0].delta.content end' \
    | tee $output_file
    echo
fi
