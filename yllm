#!/bin/bash

YLLM_MAX_TOKENS=4096
YLLM_TEMPERATURE=0.1
YLLM_TOP_P=0.9

RAW_STREAM=false

function print_help() {
  cat <<EOF
Usage: $0 [options] [--] [prompt]

Options:
  -h, --help                Print this help text and exit.
  -s, --settings <file>     Load YLLM_* env settings from the given file.
  -a, --api-url <url>       The API URL to use (default: $YLLM_API_URL).
  -k, --api-key <key>       The API key to use (default: $YLLM_API_KEY).
  -m, --model <model>       The model to use for the completion (default: $YLLM_MODEL).
  -t, --temperature <t      The temperature for the model (default: $TEMPERATURE).
  -p, --top-p <p>           The top-p value for the model (default: $TOP_P).
  -l, --max-tokens <n>      The maximum number of tokens to generate (default: $MAX_TOKENS).
  -c, --stdin               Read data from standard input.
  -u, --url <url>           Read text data from the given URL.
  -f, --file <file>         Read text data from the given file.
  -d, --dump-prompt         Write the prompt to stdout and exit.
  -r, --raw-stream          Show the raw JSONL stream from the API.

If no prompt is provided, read from standard input.
The prompt is built from input arguments in the order they are provided.
EOF
}

# no arguments, print help
if [[ $# -eq 0 ]]; then
  print_help
  exit 0
fi

# Parse command line arguments and flags
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            print_help
            exit 0
            ;;
        -s|--settings)
            SETTINGS_FILE="$2"
            # Check if the specified settings file exists in the current directory
            if [[ -f "$SETTINGS_FILE" ]]; then
                source "$SETTINGS_FILE"
            # If not found, check in the ~/.yllm directory
            elif [[ -f "$HOME/.yllm/$SETTINGS_FILE" ]]; then
                source "$HOME/.yllm/$SETTINGS_FILE"
            else
                echo "Settings file not found: $SETTINGS_FILE"
                exit 1
            fi
            shift # past argument
            shift # past value
            ;;
        -a|--api-url)
            YLLM_API_URL="$2"
            shift # past argument
            shift # past value
            ;;
        -k|--api-key)
            YLLM_API_KEY="$2"
            shift # past argument
            shift # past value
            ;;
        -m|--model)
            YLLM_MODEL="$2"
            shift # past argument
            shift # past value
            ;;
        -t|--temperature)
            YLLM_TEMPERATURE="$2"
            shift # past argument
            shift # past value
            ;;
        -p|--top-p)
            YLLM_TOP_P="$2"
            shift # past argument
            shift # past value
            ;;
        -l|--max-tokens)
            YLLM_MAX_TOKENS="$2"
            shift # past argument
            shift # past value
            ;;

        -c|--stdin)
            STDIN_CONTENT=$(cat)
            inputs+=("$STDIN_CONTENT")
            shift # past argument
            ;;
        -u|--url)
            URL_CONTENT="$(curl -s "$2" | lynx -stdin -dump)"
            inputs+=("$URL_CONTENT")
            shift # past argument
            shift # past value
            ;;
        -f|--file)
            FILE="$2"
            mimetype=$(file -b --mime-type "$FILE")
            if [[ $mimetype == text/* ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "inode/symlink" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/pdf" ]]; then
                FILE_CONTENT="$(pdftotext "$FILE" -)"
            elif [[ $mimetype == "application/json" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/javascript" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/epub+zip" ]] \
                || [[ $mimetype == "application/vnd.openxmlformats-officedocument.wordprocessingml.document" ]] \
                || [[ $mimetype == "application/msword" ]] \
                || [[ $mimetype == "application/postscript" ]]; then
                FILE_CONTENT="$(pandoc -s "$FILE" -t plain -o -)"
            else
                echo "Unsupported file type: $(file -b --mime-type "$FILE")"
                exit 1
            fi
            inputs+=("$FILE_CONTENT")
            shift # past argument
            shift # past value
            ;;
        -d|--dump-prompt)
            DUMP_PROMPT=true
            shift # past argument
            ;;
        -r|--raw-stream)
            RAW_STREAM=true
            shift # past argument
            ;;
        *)
            inputs+=("$1")
            shift # past argument
            ;;
    esac
done

if [[ $DUMP_PROMPT = false ]]; then
  # if no model has been specified
  if [[ -z "$YLLM_MODEL" ]]; then
    echo "No model specified. Please set the YLLM_MODEL environment variable, use the -m option, or specify a config file."
    exit 1
  fi
fi

# if we should dump the prompt
if [[ $DUMP_PROMPT ]]; then
    printf "%s\n" "${inputs[@]}"
    exit 0
fi

unbuffer="stdbuf -o0 -i0"

send_request() {
    prompt="$1"
    if [[ $YLLM_DEEPINFRA_MODE ]]; then
    prompt=$(echo "$prompt" | sed -e 's/\[INST\]//g' -e 's/\[\/INST\]//g')
    json_payload='{
        "input": '$prompt',
        "stream": true
    }'
    elif [[ $YLLM_COHERE_WEB_MODE ]]; then
    json_payload=$(printf '{
        "message": %s,
        "stream": true,
        "connectors": [{"id": "web-search"}],
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    elif [[ $YLLM_COHERE_MODE ]]; then
    json_payload=$(printf '{
        "message": %s,
        "stream": true,
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    else
    json_payload=$(printf '{
        "messages": [
            {
                "role": "user",
                "content": %s
            }
        ],
        "model": "%s",
        "stream": true,
        "n": 1,
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" "$YLLM_MODEL" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P )
    fi

    temp_file=$(mktemp)
    echo "$json_payload" > "$temp_file"

    cleanup() {
        [[ -n $temp_file && -f $temp_file ]] && rm -f "$temp_file"
    }

    trap cleanup EXIT

    cat $temp_file

    $unbuffer curl --request POST \
         --silent \
         --url "$YLLM_API_URL" \
         -H 'content-Type: application/json' \
         -H "authorization: Bearer $YLLM_API_KEY" \
         $YLLM_EXTRA_CURL_FLAGS \
         --data @"$temp_file"
}

COMPLETE_PROMPT=$(printf "%s\n" "${inputs[@]}" | jq -sR .)

if [[ $RAW_STREAM = true ]]; then
    send_request "$COMPLETE_PROMPT"
    exit 0
fi

# Send the request and extract the response
# do this if we're not in deepinfra mode
if [[ $YLLM_DEEPINFRA_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer sed 's%</s>"%"%' \
    | $unbuffer sed 's/^data: //g' | $unbuffer sed 's/\[DONE\]//' \
    | $unbuffer jq -j --unbuffered 'select(.token.text != null) | .token.text'
elif [[ $YLLM_COHERE_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer jq -j --unbuffered 'select(.event_type == "text-generation") | if .is_finished then "\n" else .text end'
else
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer sed 's%</s>"%"%' \
    | $unbuffer sed 's/^data: //g' | $unbuffer sed 's/\[DONE\]//' \
    | $unbuffer jq -j --unbuffered 'select(.choices[0].delta.content != null) | if .choices[0].finish_reason == "stop" then .choices[0].delta.content + "\n" else .choices[0].delta.content end'
fi
